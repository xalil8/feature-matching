{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\n",
    "    \"a101\": {\n",
    "        \"images\": {\n",
    "            \"a101_suvgsjdgjweg\": {\"image_path\": \"./dataset/train/images/a101_suvgsjdgjweg.png\", \"txt_path\": \"./dataset/train/images/a101_suvgsjdgjweg.txt\"},\n",
    "            \"a101_suvgadgsjdgjweg\" : {\"image_path\": \"./dataset/train/images/a101_suvgadgsjdgjweg.png\", \"txt_path\": \"./dataset/train/images/a101_suvgadgsjdgjweg.txt\"}\n",
    "            },\n",
    "\n",
    "        \"cropped_logo_images\": {\n",
    "            \"./cropped_images/a101_18.jpg\":{ \"size\": {\"x\": 100, \"y\": 50}, \"source_image\": \"./dataset/train/images/a101_suvgsjdgjweg.png\", \"image\": image[x:w, y:h]},\n",
    "            \"./cropped_images/a101_18.jpg\":{ \"size\": {\"x\": 100, \"y\": 50}, \"source_image\": \"./dataset/train/images/a101_suvgsjdgjweg.png\", \"image\": image[x:w, y:h]},\n",
    "            \"a101_18.jpg\": { \"size\": {\"x\": 100, \"y\": 50}, \"source_image\": \"a\"},\n",
    "            \"a101_18.jpg\": { \"size\": {\"x\": 100, \"y\": 50}, \"source_image\": \"a\"},\n",
    "            \"a101_18.jpg\": { \"size\": {\"x\": 100, \"y\": 50}, \"source_image\": \"a\"}\n",
    "            },\n",
    "        \"avarage_size\": {\"x\": 100, \"y\": 50},\n",
    "        }\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalde datasetin içerisinde valid ve traini okuyup whole dosyasına birleştiriyorsun\n",
    "\n",
    "dataset_folder_path = \"./datasets\"\n",
    "os.listdir(\"\")\n",
    "a101 \n",
    "\n",
    "dict.setdefault(logo, {})\n",
    "dict[logo_adi].setdefault(\"images\", [])\n",
    "\n",
    "dict[logo_adi][\"images\"].append(\n",
    "    {\n",
    "        \"image_path\": \"\",\n",
    "        \"txt_path\": \"\"\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "for logo_name, data in dict.items():\n",
    "    for image in data[\"images\"]:\n",
    "        cv2.readimage[\"image_path\"]\n",
    "        open image[\"txt_path\"]\n",
    "\n",
    "        data.setdefault(\"cropped_logo_images\", [])\n",
    "\n",
    "\n",
    "# \n",
    "images = [\n",
    "    \"./dataset/train/images/a101....\",\n",
    "    \"./dataset/valid/images/a101....\"\n",
    "]\n",
    "\n",
    "d = {\n",
    "    \"a101\": {\n",
    "        \"images\": {\n",
    "            \"a101_suvgsjdgjweg\": {\"image_path\": \"./dataset/train/images/a101_suvgsjdgjweg.png\", \"txt_path\": \"./dataset/train/images/a101_suvgsjdgjweg.txt\"},\n",
    "            \"a101_suvgadgsjdgjweg\" : {\"image_path\": \"./dataset/train/images/a101_suvgadgsjdgjweg.png\", \"txt_path\": \"./dataset/train/images/a101_suvgadgsjdgjweg.txt\"}\n",
    "            },\n",
    "\n",
    "        \"cropped_logo_images\": [\n",
    "            {\"path\": \"./cropped_images/a101_18.jpg\", \"size\": {\"x\": 100, \"y\": 50}, \"source_image\": \"./dataset/train/images/a101_suvgsjdgjweg.png\", \"image\": image[x:w, y:h]},\n",
    "            {\"path\": \"a101_18.jpg\", \"size\": {\"x\": 100, \"y\": 50}, \"source_image\": \"\"},\n",
    "            {\"path\": \"a101_18.jpg\", \"size\": {\"x\": 100, \"y\": 50}, \"source_image\": \"\"},\n",
    "            {\"path\": \"a101_18.jpg\", \"size\": {\"x\": 100, \"y\": 50}, \"source_image\": \"\"},\n",
    "            {\"path\": \"a101_18.jpg\", \"size\": {\"x\": 100, \"y\": 50}, \"source_image\": \"\"},\n",
    "            {\"path\": \"a101_18.jpg\", \"size\": {\"x\": 100, \"y\": 50}, \"source_image\": \"\"}\n",
    "            ],\n",
    "        \"avarage_size\": {\"x\": 100, \"y\": 50}\n",
    "        }\n",
    "    \n",
    "}\n",
    "\n",
    "d[\"a\"][\"b\"][\"c\"][3]\n",
    "\n",
    "json.dumps(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whole dosyası içerisindeki resimleri okuyorsun ve ardından bunların logolarını croplayıp kaydediyorsun\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "for txt_file_name in chain(sorted(os.listdir(img_folder_path1)),sorted(os.listdir(img_folder_path2))):\n",
    "        img_name_short = txt_file_name.split('_')[0]\n",
    "        print(txt_file_name)\n",
    "        if \n",
    "\n",
    "try:\n",
    "    with open(txt_file_name) as f:\n",
    "        lines = f.read().strip().split('\\n')\n",
    "    \n",
    "    for line in lines:\n",
    "        class_name, x, y, w, h = line.strip().split()\n",
    "\n",
    "except ValueError:\n",
    "    print(\"error\")\n",
    "\n",
    "    #my_dict[class_name][\"images\"].update({img_name:{}})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,yaml,shutil,cv2\n",
    "from itertools import chain\n",
    "\n",
    "\n",
    "with open(\"dataset/data.yaml\", 'r') as file:\n",
    "    # load the contents of the file into a Python object\n",
    "    data = yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "# extract the names from the data\n",
    "class_yaml = data[\"names\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create empty main dictionary with empty inner dictionaries\n",
    "my_dict = {}\n",
    "\n",
    "\n",
    "txt_folder_path1 = \"dataset/train/labels/\"\n",
    "txt_folder_path2 = \"dataset/valid/labels/\"\n",
    "cropped_folder_path = \"cropped/\"\n",
    "counter = 0\n",
    "\n",
    "\n",
    "for class_name in class_yaml:\n",
    "    my_dict.setdefault(class_name, {})\n",
    "    my_dict[class_name].update({\"images\":{},\"cropped_logo_images\":{},\"average_size\":{}})\n",
    "\n",
    "#my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create rem_dictionary , for each class, add files names which has contain that class labels in it \n",
    "rem_dict ={} \n",
    "for class_name in class_yaml:\n",
    "    rem_dict.setdefault(class_name, [])\n",
    "\n",
    "counter = 0\n",
    "for path in [txt_folder_path1,txt_folder_path2]:\n",
    "\n",
    "    #for txt_file_name in chain(sorted(os.listdir(img_folder_path1)),sorted(os.listdir(img_folder_path2))):\n",
    "    for txt_file_name in os.listdir(path):\n",
    "        #img_name_short = txt_file_name.split('_')[0]\n",
    "\n",
    "        try:\n",
    "            with open(path+txt_file_name) as f:\n",
    "                lines = f.read().strip().split('\\n')\n",
    "            \n",
    "            for line in lines:\n",
    "                counter +=1\n",
    "                print(counter)\n",
    "                \n",
    "                class_order, x, y, w, h = line.strip().split()\n",
    "                label_name = class_yaml[int(class_order)]\n",
    "                x, y, w, h = float(x), float(y), float(w), float(h)\n",
    "                x1, y1, x2, y2 = round((x-w/2) * 1280), round((y-h/2) * 720), round((x+w/2) * 1280), round((y+h/2) * 720)\n",
    "                \n",
    "                jpg_path = path.replace(\"labels\",\"images\")+ txt_file_name.replace('.txt', '.jpg')\n",
    "                \n",
    "                #image cropping and saving \n",
    "                #img = cv2.imread(jpg_path)\n",
    "                #cropped_img = img[y1:y2, x1:x2]\n",
    "                cropped_img_name = f\"{label_name}_{counter}.jpg\"\n",
    "                cropped_img_path = os.path.join(cropped_folder_path, cropped_img_name)\n",
    "\n",
    "                #my_dict[label_name][\"cropped_logo_images\"].append({\"cropped_path\":cropped_img_path,\"size\":{\"x\":x2-x1,\"y\":y2-y1},\"source_image\":jpg_path})\n",
    "                my_dict[label_name][\"cropped_logo_images\"].update({cropped_img_path:{\"size\":{\"x\":x2-x1,\"y\":y2-y1},\"source_image\":jpg_path}})\n",
    "\n",
    "                \n",
    "                rem_dict[label_name].append(txt_file_name)\n",
    "\n",
    "        except ValueError:\n",
    "            #print(\"error\")\n",
    "            pass\n",
    "        \n",
    "#rem_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to add images from rem_dict\n",
    "for i in rem_dict:\n",
    "    my_dict[i].update({\"images\":rem_dict[i]})\n",
    "del rem_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for q in my_dict:\n",
    "    x_sum,y_sum=0,0\n",
    "    for m in my_dict[q][\"cropped_logo_images\"]:\n",
    "        div = len(my_dict[q][\"cropped_logo_images\"])\n",
    "        x_sum += my_dict[q][\"cropped_logo_images\"][m][\"size\"][\"x\"]\n",
    "        y_sum += my_dict[q][\"cropped_logo_images\"][m][\"size\"][\"y\"]\n",
    "    x_avg, y_avg = round(x_sum/div), round(y_sum/div)\n",
    "    my_dict[q][\"average_size\"].update({\"x\":x_avg,\"y\":y_avg})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict[\"A-T-bank\"][\"cropped_logo_images\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "98590ff4fe04c8543246b2a01debd3de3c5ca9b666f43f1fa87d5110c692004c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
