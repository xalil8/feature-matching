{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\n",
    "    \"a101\": {\n",
    "        \"images\": {\n",
    "            \"a101_suvgsjdgjweg\": {\"image_path\": \"./dataset/train/images/a101_suvgsjdgjweg.png\", \"txt_path\": \"./dataset/train/images/a101_suvgsjdgjweg.txt\"},\n",
    "            \"a101_suvgadgsjdgjweg\" : {\"image_path\": \"./dataset/train/images/a101_suvgadgsjdgjweg.png\", \"txt_path\": \"./dataset/train/images/a101_suvgadgsjdgjweg.txt\"}\n",
    "            },\n",
    "\n",
    "        \"cropped_logo_images\": {\n",
    "            \"cropped_images/a101_18.jpg\":{ \"size\": {\"x\": 100, \"y\": 50}, \"source_image\": \"./dataset/train/images/a101_suvgsjdgjweg.png\", \"image\": image[x:w, y:h]},\n",
    "            \"cropped_images/a101_18.jpg\":{ \"size\": {\"x\": 100, \"y\": 50}, \"source_image\": \"./dataset/train/images/a101_suvgsjdgjweg.png\", \"image\": image[x:w, y:h]},\n",
    "            \"a101_18.jpg\": { \"size\": {\"x\": 100, \"y\": 50}, \"source_image\": \"a\"},\n",
    "            \"a101_18.jpg\": { \"size\": {\"x\": 100, \"y\": 50}, \"source_image\": \"a\"},\n",
    "            \"a101_18.jpg\": { \"size\": {\"x\": 100, \"y\": 50}, \"source_image\": \"a\"}\n",
    "            },\n",
    "        \"avarage_size\": {\"x\": 100, \"y\": 50},\n",
    "        }\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalde datasetin içerisinde valid ve traini okuyup whole dosyasına birleştiriyorsun\n",
    "\n",
    "dataset_folder_path = \"./datasets\"\n",
    "os.listdir(\"\")\n",
    "a101 \n",
    "\n",
    "dict.setdefault(logo, {})\n",
    "dict[logo_adi].setdefault(\"images\", [])\n",
    "\n",
    "dict[logo_adi][\"images\"].append(\n",
    "    {\n",
    "        \"image_path\": \"\",\n",
    "        \"txt_path\": \"\"\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "for logo_name, data in dict.items():\n",
    "    for image in data[\"images\"]:\n",
    "        cv2.readimage[\"image_path\"]\n",
    "        open image[\"txt_path\"]\n",
    "\n",
    "        data.setdefault(\"cropped_logo_images\", [])\n",
    "\n",
    "\n",
    "# \n",
    "images = [\n",
    "    \"./dataset/train/images/a101....\",\n",
    "    \"./dataset/valid/images/a101....\"\n",
    "]\n",
    "\n",
    "d = {\n",
    "    \"a101\": {\n",
    "\n",
    "        \"images\": {\n",
    "            \"a101_suvgsjdgjweg\": {\"image_path\": \"./dataset/train/images/a101_suvgsjdgjweg.png\", \"txt_path\": \"./dataset/train/images/a101_suvgsjdgjweg.txt\"},\n",
    "            \"a101_suvgadgsjdgjweg\" : {\"image_path\": \"./dataset/train/images/a101_suvgadgsjdgjweg.png\", \"txt_path\": \"./dataset/train/images/a101_suvgadgsjdgjweg.txt\"}\n",
    "            },\n",
    "\n",
    "        \"cropped_logo_images\": [\n",
    "            {\"path\": \"./cropped_images/a101_18.jpg\", \"size\": {\"x\": 100, \"y\": 50}, \"source_image\": \"./dataset/train/images/a101_suvgsjdgjweg.png\"},\n",
    "            {\"path\": \"a101_18.jpg\", \"size\": {\"x\": 100, \"y\": 50}, \"source_image\": \"\"},\n",
    "            {\"path\": \"a101_18.jpg\", \"size\": {\"x\": 100, \"y\": 50}, \"source_image\": \"\"},\n",
    "            {\"path\": \"a101_18.jpg\", \"size\": {\"x\": 100, \"y\": 50}, \"source_image\": \"\"},\n",
    "            {\"path\": \"a101_18.jpg\", \"size\": {\"x\": 100, \"y\": 50}, \"source_image\": \"\"},\n",
    "            {\"path\": \"a101_18.jpg\", \"size\": {\"x\": 100, \"y\": 50}, \"source_image\": \"\"}\n",
    "            ],\n",
    "            \n",
    "        \"avarage_size\": {\"x\": 100, \"y\": 50},\n",
    "\n",
    "        \"counter\":0\n",
    "        } \n",
    "}   \n",
    "\n",
    "\n",
    "\n",
    "json.dumps(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whole dosyası içerisindeki resimleri okuyorsun ve ardından bunların logolarını croplayıp kaydediyorsun\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "for txt_file_name in chain(sorted(os.listdir(img_folder_path1)),sorted(os.listdir(img_folder_path2))):\n",
    "        img_name_short = txt_file_name.split('_')[0]\n",
    "        print(txt_file_name)\n",
    "        if \n",
    "\n",
    "try:\n",
    "    with open(txt_file_name) as f:\n",
    "        lines = f.read().strip().split('\\n')\n",
    "    \n",
    "    for line in lines:\n",
    "        class_name, x, y, w, h = line.strip().split()\n",
    "\n",
    "except ValueError:\n",
    "    print(\"error\")\n",
    "\n",
    "    #my_dict[class_name][\"images\"].update({img_name:{}})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,yaml,shutil,cv2\n",
    "from itertools import chain\n",
    "\n",
    "\n",
    "with open(\"dataset/data.yaml\", 'r') as file:\n",
    "    # load the contents of the file into a Python object\n",
    "    data = yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "# extract the names from the data\n",
    "class_yaml = data[\"names\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create empty main dictionary with empty inner dictionaries\n",
    "my_dict = {}\n",
    "\n",
    "#todo \n",
    "#path = \"dataset\"\n",
    "\n",
    "\n",
    "txt_folder_path1 = \"dataset/train/labels/\"\n",
    "txt_folder_path2 = \"dataset/valid/labels/\"\n",
    "cropped_folder_path = \"cropped/\"\n",
    "\n",
    "\n",
    "\n",
    "for class_name in class_yaml:\n",
    "    my_dict.setdefault(class_name, {})\n",
    "    my_dict[class_name].update({\"images\":{},\"cropped_logo_images\":{},\"average_size\":{},\"counter\":1})\n",
    "\n",
    "#my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create rem_dictionary , for each class, add files names which has contain that class labels in it \n",
    "rem_dict ={} \n",
    "for class_name in class_yaml:\n",
    "    rem_dict.setdefault(class_name, [])\n",
    "\n",
    "\n",
    "\n",
    "process_counter = 0\n",
    "for path in [txt_folder_path1,txt_folder_path2]:\n",
    "    \"\"\"if path==txt_folder_path1:\n",
    "        continue\"\"\"\n",
    "\n",
    "    #for txt_file_name in chain(sorted(os.listdir(img_folder_path1)),sorted(os.listdir(img_folder_path2))):\n",
    "    for txt_file_name in os.listdir(path):\n",
    "        #img_name_short = txt_file_name.split('_')[0]\n",
    "        jpg_path = path.replace(\"labels\",\"images\")+ txt_file_name.replace('.txt', '.jpg')\n",
    "        try:\n",
    "            #print(path+txt_file_name)\n",
    "            with open(path+txt_file_name) as f:\n",
    "                lines = f.read().strip().split('\\n')\n",
    "            \n",
    "            for line in lines:\n",
    "                process_counter +=1\n",
    "                if process_counter %100 ==0:\n",
    "                    print(process_counter)\n",
    "                \n",
    "                class_order, x, y, w, h = line.strip().split()\n",
    "                label_name = class_yaml[int(class_order)]\n",
    "                x, y, w, h = float(x), float(y), float(w), float(h)\n",
    "                x1, y1, x2, y2 = round((x-w/2) * 1280), round((y-h/2) * 720), round((x+w/2) * 1280), round((y+h/2) * 720)\n",
    "                \n",
    "                \n",
    "                \n",
    "                #image cropping and saving \n",
    "                \n",
    "                \n",
    "                counter = my_dict[label_name][\"counter\"]\n",
    "\n",
    "                cropped_img_name = f\"{label_name}_{counter}.jpg\"\n",
    "                cropped_img_path = os.path.join(cropped_folder_path, cropped_img_name)\n",
    "\n",
    "                #my_dict[label_name][\"cropped_logo_images\"].append({\"cropped_path\":cropped_img_path,\"size\":{\"x\":x2-x1,\"y\":y2-y1},\"source_image\":jpg_path})\n",
    "                my_dict[label_name][\"cropped_logo_images\"].update({cropped_img_path:{\"size\":{\"x\":x2-x1,\"y\":y2-y1},\"source_image\":jpg_path}})\n",
    "                rem_dict[label_name].append(txt_file_name)\n",
    "\n",
    "                my_dict[label_name][\"counter\"] += 1\n",
    "\n",
    "        except ValueError:\n",
    "            print(\"error\")\n",
    "            pass\n",
    "        \n",
    "#rem_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to add images from rem_dict\n",
    "for i in rem_dict:\n",
    "    my_dict[i].update({\"images\":rem_dict[i]})\n",
    "#del rem_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for q in my_dict:\n",
    "    x_sum,y_sum=0,0\n",
    "    for m in my_dict[q][\"cropped_logo_images\"]:\n",
    "        div = len(my_dict[q][\"cropped_logo_images\"])\n",
    "        x_sum += int(my_dict[q][\"cropped_logo_images\"][m][\"size\"][\"x\"])\n",
    "        y_sum += my_dict[q][\"cropped_logo_images\"][m][\"size\"][\"y\"]\n",
    "    x_avg, y_avg = round(x_sum/div), round(y_sum/div)\n",
    "    my_dict[q][\"average_size\"].update({\"x\":x_avg,\"y\":y_avg})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_folder_path = \"./cropped\"\n",
    "dataset_path = \"./dataset\"\n",
    "import yaml\n",
    "for file_names in os.listdir(dataset_path):\n",
    "    if file_names.endswith(\".yaml\"):\n",
    "        yaml_path = dataset_path+\"/\"+file_names\n",
    "        #yaml_path = os.path.join(dataset_path,file_names)\n",
    "\n",
    "with open(yaml_path, 'r') as file:\n",
    "    # load the contents of the file into a Python object\n",
    "    data = yaml.load(file, Loader=yaml.FullLoader)\n",
    "class_yaml = data[\"names\"]\n",
    "\n",
    "class_yaml\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dataset/data.yaml\", 'r') as file:\n",
    "    # load the contents of the file into a Python object\n",
    "    data = yaml.load(file, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "error\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "error\n",
      "error\n",
      "error\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "1400\n",
      "error\n",
      "1500\n",
      "error\n",
      "error\n",
      "error\n",
      "1600\n",
      "error\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "error\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "error\n",
      "error\n",
      "error\n",
      "2700\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "error\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "error\n",
      "error\n",
      "7100\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "7200\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "7300\n",
      "error\n",
      "7400\n",
      "error\n",
      "7500\n",
      "100 image are resized\n",
      "200 image are resized\n",
      "300 image are resized\n",
      "400 image are resized\n",
      "500 image are resized\n",
      "600 image are resized\n",
      "700 image are resized\n",
      "800 image are resized\n",
      "900 image are resized\n",
      "1000 image are resized\n",
      "1100 image are resized\n",
      "1200 image are resized\n",
      "1300 image are resized\n",
      "1400 image are resized\n",
      "1500 image are resized\n",
      "1600 image are resized\n",
      "1700 image are resized\n",
      "1800 image are resized\n",
      "1900 image are resized\n",
      "2000 image are resized\n",
      "2100 image are resized\n",
      "2200 image are resized\n",
      "2300 image are resized\n",
      "2400 image are resized\n",
      "2500 image are resized\n",
      "2600 image are resized\n",
      "2700 image are resized\n",
      "2800 image are resized\n",
      "2900 image are resized\n",
      "3000 image are resized\n",
      "3100 image are resized\n",
      "3200 image are resized\n",
      "3300 image are resized\n",
      "3400 image are resized\n",
      "3500 image are resized\n",
      "3600 image are resized\n",
      "3700 image are resized\n",
      "3800 image are resized\n",
      "3900 image are resized\n",
      "4000 image are resized\n",
      "4100 image are resized\n",
      "4200 image are resized\n",
      "4300 image are resized\n",
      "4400 image are resized\n",
      "4500 image are resized\n",
      "4600 image are resized\n",
      "4700 image are resized\n",
      "4800 image are resized\n",
      "4900 image are resized\n",
      "5000 image are resized\n",
      "5100 image are resized\n",
      "5200 image are resized\n",
      "5300 image are resized\n",
      "5400 image are resized\n",
      "5500 image are resized\n",
      "5600 image are resized\n",
      "5700 image are resized\n",
      "5800 image are resized\n",
      "5900 image are resized\n",
      "6000 image are resized\n",
      "6100 image are resized\n",
      "6200 image are resized\n",
      "6300 image are resized\n",
      "6400 image are resized\n",
      "6500 image are resized\n",
      "6600 image are resized\n",
      "6700 image are resized\n",
      "6800 image are resized\n",
      "6900 image are resized\n",
      "7000 image are resized\n",
      "7100 image are resized\n",
      "7200 image are resized\n",
      "7300 image are resized\n",
      "7400 image are resized\n",
      "7500 image are resized\n"
     ]
    }
   ],
   "source": [
    "import os,yaml,shutil,cv2\n",
    "from itertools import chain\n",
    "\n",
    "cropped_folder_path = \"./cropped2\"\n",
    "dataset_path = \"./dataset\"\n",
    "\n",
    "#resized_path = \"reshaped/\"\n",
    "\n",
    "my_dict = {}\n",
    "rem_dict ={} \n",
    "\n",
    "##########read yaml file to get class information #################\n",
    "\n",
    "for file_names in os.listdir(dataset_path):\n",
    "    if file_names.endswith(\".yaml\"):\n",
    "        yaml_path = dataset_path+\"/\"+file_names\n",
    "        #yaml_path = os.path.join(dataset_path,file_names)\n",
    "\n",
    "with open(yaml_path, 'r') as file:\n",
    "    # load the contents of the file into a Python object\n",
    "    data = yaml.load(file, Loader=yaml.FullLoader)\n",
    "class_yaml = data[\"names\"]\n",
    "\n",
    "##########################################################\n",
    "#create rem_dictionary , for each class, add files names which has contain that class labels in it \n",
    "\n",
    "for class_name in class_yaml:\n",
    "    rem_dict.setdefault(class_name, [])\n",
    "    my_dict.setdefault(class_name, {})\n",
    "    my_dict[class_name].update({\"images\":{},\"cropped_logo_images\":[],\"average_size\":{},\"counter\":1})\n",
    "\n",
    "###################################################\n",
    "\n",
    "process_counter = 0\n",
    "\n",
    "for my_folder in os.listdir(dataset_path):\n",
    "    #check if file is folder \n",
    "    #sub_folder = os.path.join(dataset_path, my_folder)\n",
    "    sub_folder = dataset_path+\"/\"+my_folder\n",
    "    if os.path.isdir(sub_folder):\n",
    "        for txt_file_name in os.listdir(os.path.join(dataset_path, my_folder)+\"\\labels\"):\n",
    "\n",
    "            #img_name_short = txt_file_name.split('_')[0]\n",
    "            jpg_path = sub_folder+\"/images/\"+ txt_file_name.replace('.txt', '.jpg')\n",
    "  \n",
    "            img = cv2.imread(jpg_path)\n",
    "            try:\n",
    "                \n",
    "                with open(sub_folder+\"/labels/\"+txt_file_name) as f:\n",
    "                    lines = f.read().strip().split('\\n')\n",
    "                \n",
    "                for line in lines:\n",
    "                    process_counter +=1\n",
    "                    if process_counter %100 ==0:\n",
    "                        print(process_counter)\n",
    "                    \n",
    "                    class_order, x, y, w, h = line.strip().split()\n",
    "                    label_name = class_yaml[int(class_order)]\n",
    "                    x, y, w, h = float(x), float(y), float(w), float(h)\n",
    "                    x1, y1, x2, y2 = round((x-w/2) * 1280), round((y-h/2) * 720), round((x+w/2) * 1280), round((y+h/2) * 720)\n",
    "                    \n",
    "                    #image cropping and saving \n",
    "                    \n",
    "                    \n",
    "                    counter = my_dict[label_name][\"counter\"]\n",
    "\n",
    "                    cropped_img_name = f\"{label_name}_{counter}.jpg\"\n",
    "                    #cropped_img_path = os.path.join(cropped_folder_path, cropped_img_name)\n",
    "                    cropped_img_path = cropped_folder_path+\"/\"+cropped_img_name\n",
    "\n",
    "                    my_dict[label_name][\"cropped_logo_images\"].append({\"cropped_path\":cropped_img_path,\"size\":{\"x\":x2-x1,\"y\":y2-y1},\"source_image\":jpg_path})\n",
    "                    \n",
    "                    #my_dict[label_name][\"cropped_logo_images\"].update({cropped_img_path:{\"size\":{\"x\":x2-x1,\"y\":y2-y1},\"source_image\":jpg_path}})\n",
    "                    \n",
    "                    rem_dict[label_name].append(sub_folder+\"/images/\"+ txt_file_name.replace('.txt', '.jpg'))\n",
    "\n",
    "                    my_dict[label_name][\"counter\"] += 1\n",
    "                    cropped_img = img[y1:y2, x1:x2]\n",
    "                    cv2.imwrite(cropped_img_path, cropped_img)\n",
    "\n",
    "            except ValueError:\n",
    "                print(\"error\",\"image doesnt have logo\")\n",
    "                pass\n",
    "\n",
    "##################################################################        \n",
    "#to add images from rem_dict\n",
    "for i in rem_dict:\n",
    "    my_dict[i].update({\"images\":rem_dict[i]})\n",
    "del rem_dict\n",
    "\n",
    "#GET AVERAGE OF CROPPED SIZE BY CLASS#\n",
    "##################################################################\n",
    "for q in my_dict:\n",
    "    x_sum,y_sum=0,0\n",
    "    for m in my_dict[q][\"cropped_logo_images\"]:\n",
    "        div = len(my_dict[q][\"cropped_logo_images\"])\n",
    "        #used for {} cropped images\n",
    "        #x_sum += my_dict[q][\"cropped_logo_images\"][m][\"size\"][\"x\"]\n",
    "\n",
    "        x_sum += m[\"size\"][\"x\"]\n",
    "        y_sum += m[\"size\"][\"y\"]\n",
    "    x_avg, y_avg = round(x_sum/div), round(y_sum/div)\n",
    "    my_dict[q][\"average_size\"].update({\"x\":x_avg,\"y\":y_avg})\n",
    "#####################################################################\n",
    "#to clear duplicate image names in images dict\n",
    "for classes in my_dict:\n",
    "    my_dict[classes][\"images\"] = [*{*my_dict[classes][\"images\"]}]\n",
    "\n",
    "#############Reshaping cropped imaged in scale of average #############\n",
    "counter = 0\n",
    "for clas_name in my_dict:\n",
    "    avg_size =  (my_dict[clas_name][\"average_size\"][\"x\"],my_dict[clas_name][\"average_size\"][\"y\"])\n",
    "    #print(avg_size)\n",
    "    for image_path in my_dict[clas_name][\"cropped_logo_images\"]:\n",
    "    \n",
    "        img = cv2.imread(image_path[\"cropped_path\"])  \n",
    "        img_resized = cv2.resize(img, avg_size)\n",
    "        cv2.imwrite(image_path[\"cropped_path\"], img_resized)\n",
    "\n",
    "        counter+=1\n",
    "        if counter%100 ==0:\n",
    "            print(counter,\"image are resized\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#counter = 0\n",
    "\n",
    "counter = 0\n",
    "for clas_name in my_dict:\n",
    "    avg_size =  (my_dict[clas_name][\"average_size\"][\"x\"],my_dict[clas_name][\"average_size\"][\"y\"])\n",
    "    #print(avg_size)\n",
    "    for image_path in my_dict[clas_name][\"cropped_logo_images\"]:\n",
    "    \n",
    "        img = cv2.imread(image_path[\"cropped_path\"])  \n",
    "        img_resized = cv2.resize(img, avg_size)\n",
    "        cv2.imwrite(image_path[\"cropped_path\"], img_resized)\n",
    "\n",
    "        counter+=1\n",
    "        if counter%100 ==0:\n",
    "            print(counter,\"image are resized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "570feb405e2e27c949193ac68f46852414290d515b0ba6e5d90d076ed2284471"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
