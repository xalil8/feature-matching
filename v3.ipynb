{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\n",
    "    \"a101\": {\n",
    "        \"images\": {\n",
    "            \"a101_suvgsjdgjweg\": {\"image_path\": \"./dataset/train/images/a101_suvgsjdgjweg.png\", \"txt_path\": \"./dataset/train/images/a101_suvgsjdgjweg.txt\"},\n",
    "            \"a101_suvgadgsjdgjweg\" : {\"image_path\": \"./dataset/train/images/a101_suvgadgsjdgjweg.png\", \"txt_path\": \"./dataset/train/images/a101_suvgadgsjdgjweg.txt\"}\n",
    "            },\n",
    "\n",
    "        \"cropped_logo_images\": {\n",
    "            \"cropped_images/a101_18.jpg\":{ \"size\": {\"x\": 100, \"y\": 50}, \"source_image\": \"./dataset/train/images/a101_suvgsjdgjweg.png\", \"image\": image[x:w, y:h]},\n",
    "            \"cropped_images/a101_18.jpg\":{ \"size\": {\"x\": 100, \"y\": 50}, \"source_image\": \"./dataset/train/images/a101_suvgsjdgjweg.png\", \"image\": image[x:w, y:h]},\n",
    "            \"a101_18.jpg\": { \"size\": {\"x\": 100, \"y\": 50}, \"source_image\": \"a\"},\n",
    "            \"a101_18.jpg\": { \"size\": {\"x\": 100, \"y\": 50}, \"source_image\": \"a\"},\n",
    "            \"a101_18.jpg\": { \"size\": {\"x\": 100, \"y\": 50}, \"source_image\": \"a\"}\n",
    "            },\n",
    "        \"avarage_size\": {\"x\": 100, \"y\": 50},\n",
    "        }\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalde datasetin içerisinde valid ve traini okuyup whole dosyasına birleştiriyorsun\n",
    "\n",
    "dataset_folder_path = \"./datasets\"\n",
    "os.listdir(\"\")\n",
    "a101 \n",
    "\n",
    "dict.setdefault(logo, {})\n",
    "dict[logo_adi].setdefault(\"images\", [])\n",
    "\n",
    "dict[logo_adi][\"images\"].append(\n",
    "    {\n",
    "        \"image_path\": \"\",\n",
    "        \"txt_path\": \"\"\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "for logo_name, data in dict.items():\n",
    "    for image in data[\"images\"]:\n",
    "        cv2.readimage[\"image_path\"]\n",
    "        open image[\"txt_path\"]\n",
    "\n",
    "        data.setdefault(\"cropped_logo_images\", [])\n",
    "\n",
    "\n",
    "# \n",
    "images = [\n",
    "    \"./dataset/train/images/a101....\",\n",
    "    \"./dataset/valid/images/a101....\"\n",
    "]\n",
    "\n",
    "d = {\n",
    "    \"a101\": {\n",
    "\n",
    "        \"images\": {\n",
    "            \"a101_suvgsjdgjweg\": {\"image_path\": \"./dataset/train/images/a101_suvgsjdgjweg.png\", \"txt_path\": \"./dataset/train/images/a101_suvgsjdgjweg.txt\"},\n",
    "            \"a101_suvgadgsjdgjweg\" : {\"image_path\": \"./dataset/train/images/a101_suvgadgsjdgjweg.png\", \"txt_path\": \"./dataset/train/images/a101_suvgadgsjdgjweg.txt\"}\n",
    "            },\n",
    "\n",
    "        \"cropped_logo_images\": [\n",
    "            {\"path\": \"./cropped_images/a101_18.jpg\", \"size\": {\"x\": 100, \"y\": 50}, \"source_image\": \"./dataset/train/images/a101_suvgsjdgjweg.png\"},\n",
    "            {\"path\": \"a101_18.jpg\", \"size\": {\"x\": 100, \"y\": 50}, \"source_image\": \"\"},\n",
    "            {\"path\": \"a101_18.jpg\", \"size\": {\"x\": 100, \"y\": 50}, \"source_image\": \"\"},\n",
    "            {\"path\": \"a101_18.jpg\", \"size\": {\"x\": 100, \"y\": 50}, \"source_image\": \"\"},\n",
    "            {\"path\": \"a101_18.jpg\", \"size\": {\"x\": 100, \"y\": 50}, \"source_image\": \"\"},\n",
    "            {\"path\": \"a101_18.jpg\", \"size\": {\"x\": 100, \"y\": 50}, \"source_image\": \"\"}\n",
    "            ],\n",
    "            \n",
    "        \"avarage_size\": {\"x\": 100, \"y\": 50},\n",
    "\n",
    "        \"counter\":0\n",
    "        } \n",
    "}   \n",
    "\n",
    "\n",
    "\n",
    "json.dumps(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whole dosyası içerisindeki resimleri okuyorsun ve ardından bunların logolarını croplayıp kaydediyorsun\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "for txt_file_name in chain(sorted(os.listdir(img_folder_path1)),sorted(os.listdir(img_folder_path2))):\n",
    "        img_name_short = txt_file_name.split('_')[0]\n",
    "        print(txt_file_name)\n",
    "        if \n",
    "\n",
    "try:\n",
    "    with open(txt_file_name) as f:\n",
    "        lines = f.read().strip().split('\\n')\n",
    "    \n",
    "    for line in lines:\n",
    "        class_name, x, y, w, h = line.strip().split()\n",
    "\n",
    "except ValueError:\n",
    "    print(\"error\")\n",
    "\n",
    "    #my_dict[class_name][\"images\"].update({img_name:{}})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,yaml,shutil,cv2\n",
    "from itertools import chain\n",
    "\n",
    "\n",
    "with open(\"dataset/data.yaml\", 'r') as file:\n",
    "    # load the contents of the file into a Python object\n",
    "    data = yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "# extract the names from the data\n",
    "class_yaml = data[\"names\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create empty main dictionary with empty inner dictionaries\n",
    "my_dict = {}\n",
    "\n",
    "#todo \n",
    "#path = \"dataset\"\n",
    "\n",
    "\n",
    "txt_folder_path1 = \"dataset/train/labels/\"\n",
    "txt_folder_path2 = \"dataset/valid/labels/\"\n",
    "cropped_folder_path = \"cropped/\"\n",
    "\n",
    "\n",
    "\n",
    "for class_name in class_yaml:\n",
    "    my_dict.setdefault(class_name, {})\n",
    "    my_dict[class_name].update({\"images\":{},\"cropped_logo_images\":{},\"average_size\":{},\"counter\":1})\n",
    "\n",
    "#my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create rem_dictionary , for each class, add files names which has contain that class labels in it \n",
    "rem_dict ={} \n",
    "for class_name in class_yaml:\n",
    "    rem_dict.setdefault(class_name, [])\n",
    "\n",
    "\n",
    "\n",
    "process_counter = 0\n",
    "for path in [txt_folder_path1,txt_folder_path2]:\n",
    "    \"\"\"if path==txt_folder_path1:\n",
    "        continue\"\"\"\n",
    "\n",
    "    #for txt_file_name in chain(sorted(os.listdir(img_folder_path1)),sorted(os.listdir(img_folder_path2))):\n",
    "    for txt_file_name in os.listdir(path):\n",
    "        #img_name_short = txt_file_name.split('_')[0]\n",
    "        jpg_path = path.replace(\"labels\",\"images\")+ txt_file_name.replace('.txt', '.jpg')\n",
    "        try:\n",
    "            #print(path+txt_file_name)\n",
    "            with open(path+txt_file_name) as f:\n",
    "                lines = f.read().strip().split('\\n')\n",
    "            \n",
    "            for line in lines:\n",
    "                process_counter +=1\n",
    "                if process_counter %100 ==0:\n",
    "                    print(process_counter)\n",
    "                \n",
    "                class_order, x, y, w, h = line.strip().split()\n",
    "                label_name = class_yaml[int(class_order)]\n",
    "                x, y, w, h = float(x), float(y), float(w), float(h)\n",
    "                x1, y1, x2, y2 = round((x-w/2) * 1280), round((y-h/2) * 720), round((x+w/2) * 1280), round((y+h/2) * 720)\n",
    "                \n",
    "                \n",
    "                \n",
    "                #image cropping and saving \n",
    "                \n",
    "                \n",
    "                counter = my_dict[label_name][\"counter\"]\n",
    "\n",
    "                cropped_img_name = f\"{label_name}_{counter}.jpg\"\n",
    "                cropped_img_path = os.path.join(cropped_folder_path, cropped_img_name)\n",
    "\n",
    "                #my_dict[label_name][\"cropped_logo_images\"].append({\"cropped_path\":cropped_img_path,\"size\":{\"x\":x2-x1,\"y\":y2-y1},\"source_image\":jpg_path})\n",
    "                my_dict[label_name][\"cropped_logo_images\"].update({cropped_img_path:{\"size\":{\"x\":x2-x1,\"y\":y2-y1},\"source_image\":jpg_path}})\n",
    "                rem_dict[label_name].append(txt_file_name)\n",
    "\n",
    "                my_dict[label_name][\"counter\"] += 1\n",
    "\n",
    "        except ValueError:\n",
    "            print(\"error\")\n",
    "            pass\n",
    "        \n",
    "#rem_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to add images from rem_dict\n",
    "for i in rem_dict:\n",
    "    my_dict[i].update({\"images\":rem_dict[i]})\n",
    "#del rem_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for q in my_dict:\n",
    "    x_sum,y_sum=0,0\n",
    "    for m in my_dict[q][\"cropped_logo_images\"]:\n",
    "        div = len(my_dict[q][\"cropped_logo_images\"])\n",
    "        x_sum += int(my_dict[q][\"cropped_logo_images\"][m][\"size\"][\"x\"])\n",
    "        y_sum += my_dict[q][\"cropped_logo_images\"][m][\"size\"][\"y\"]\n",
    "    x_avg, y_avg = round(x_sum/div), round(y_sum/div)\n",
    "    my_dict[q][\"average_size\"].update({\"x\":x_avg,\"y\":y_avg})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict[\"a101-logo\"][\"counter\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,yaml,shutil,cv2\n",
    "from itertools import chain\n",
    "\n",
    "\n",
    "with open(\"dataset/data.yaml\", 'r') as file:\n",
    "    # load the contents of the file into a Python object\n",
    "    data = yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "# extract the names from the data\n",
    "class_yaml = data[\"names\"]\n",
    "\n",
    "###################################################\n",
    "\n",
    "cropped_folder_path = \"./cropped\"\n",
    "dataset_path = \"./dataset\"\n",
    "\n",
    "my_dict = {}\n",
    "rem_dict ={} \n",
    "\n",
    "#create rem_dictionary , for each class, add files names which has contain that class labels in it \n",
    "\n",
    "for class_name in class_yaml:\n",
    "    rem_dict.setdefault(class_name, [])\n",
    "    my_dict.setdefault(class_name, {})\n",
    "    my_dict[class_name].update({\"images\":{},\"cropped_logo_images\":{},\"average_size\":{},\"counter\":1})\n",
    "\n",
    "###################################################\n",
    "\n",
    "process_counter = 0\n",
    "\n",
    "for my_folder in os.listdir(dataset_path):\n",
    "    #check if file is folder \n",
    "    #sub_folder = os.path.join(dataset_path, my_folder)\n",
    "    sub_folder = dataset_path+\"/\"+my_folder\n",
    "    if os.path.isdir(sub_folder):\n",
    "        for txt_file_name in os.listdir(os.path.join(dataset_path, my_folder)+\"\\labels\"):\n",
    "\n",
    "            #img_name_short = txt_file_name.split('_')[0]\n",
    "            jpg_path = sub_folder+\"/images/\"+ txt_file_name.replace('.txt', '.jpg')\n",
    "  \n",
    "            img = cv2.imread(jpg_path)\n",
    "            try:\n",
    "                \n",
    "                with open(sub_folder+\"/labels/\"+txt_file_name) as f:\n",
    "                    lines = f.read().strip().split('\\n')\n",
    "                \n",
    "                for line in lines:\n",
    "                    process_counter +=1\n",
    "                    if process_counter %100 ==0:\n",
    "                        print(process_counter)\n",
    "                    \n",
    "                    class_order, x, y, w, h = line.strip().split()\n",
    "                    label_name = class_yaml[int(class_order)]\n",
    "                    x, y, w, h = float(x), float(y), float(w), float(h)\n",
    "                    x1, y1, x2, y2 = round((x-w/2) * 1280), round((y-h/2) * 720), round((x+w/2) * 1280), round((y+h/2) * 720)\n",
    "                    \n",
    "                    #image cropping and saving \n",
    "                    \n",
    "                    \n",
    "                    counter = my_dict[label_name][\"counter\"]\n",
    "\n",
    "                    cropped_img_name = f\"{label_name}_{counter}.jpg\"\n",
    "                    #cropped_img_path = os.path.join(cropped_folder_path, cropped_img_name)\n",
    "                    cropped_img_path = cropped_folder_path+\"/\"+cropped_img_name\n",
    "\n",
    "                    #my_dict[label_name][\"cropped_logo_images\"].append({\"cropped_path\":cropped_img_path,\"size\":{\"x\":x2-x1,\"y\":y2-y1},\"source_image\":jpg_path})\n",
    "                    \n",
    "                    my_dict[label_name][\"cropped_logo_images\"].update({cropped_img_path:{\"size\":{\"x\":x2-x1,\"y\":y2-y1},\"source_image\":jpg_path}})\n",
    "                    \n",
    "                    rem_dict[label_name].append(sub_folder+\"/images/\"+ txt_file_name.replace('.txt', '.jpg'))\n",
    "\n",
    "                    my_dict[label_name][\"counter\"] += 1\n",
    "                    cropped_img = img[y1:y2, x1:x2]\n",
    "                    cv2.imwrite(cropped_img_path, cropped_img)\n",
    "\n",
    "            except ValueError:\n",
    "                print(\"error\")\n",
    "                pass\n",
    "\n",
    "##################################################################        \n",
    "#to add images from rem_dict\n",
    "for i in rem_dict:\n",
    "    my_dict[i].update({\"images\":rem_dict[i]})\n",
    "#del rem_dict\n",
    "##################################################################\n",
    "for q in my_dict:\n",
    "    x_sum,y_sum=0,0\n",
    "    for m in my_dict[q][\"cropped_logo_images\"]:\n",
    "        div = len(my_dict[q][\"cropped_logo_images\"])\n",
    "        x_sum += int(my_dict[q][\"cropped_logo_images\"][m][\"size\"][\"x\"])\n",
    "        y_sum += my_dict[q][\"cropped_logo_images\"][m][\"size\"][\"y\"]\n",
    "    x_avg, y_avg = round(x_sum/div), round(y_sum/div)\n",
    "    my_dict[q][\"average_size\"].update({\"x\":x_avg,\"y\":y_avg})\n",
    "#####################################################################\n",
    "#to clear duplicate image names in images dict\n",
    "for classes in my_dict:\n",
    "    my_dict[classes][\"images\"] = [*{*my_dict[classes][\"images\"]}]\n",
    "\n",
    "\n",
    "my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for my_folder in os.listdir(dataset_path):\n",
    "    #check if file is folder \n",
    "    sub_folder = os.path.join(dataset_path, my_folder)\n",
    "    if os.path.isdir(sub_folder):\n",
    "        for txt_file_name in os.listdir(os.path.join(dataset_path, my_folder)+\"\\labels\"):\n",
    "\n",
    "            #img_name_short = txt_file_name.split('_')[0]\n",
    "            jpg_path = sub_folder+\"/images/\"+ txt_file_name.replace('.txt', '.jpg')\n",
    "            print(jpg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_folder_path = \"cropped\"\n",
    "for my_folder in os.listdir(dataset_path):\n",
    "    #check if file is folder \n",
    "    sub_folder = os.path.join(dataset_path, my_folder)\n",
    "    if os.path.isdir(sub_folder):\n",
    "        for txt_file_name in os.listdir(os.path.join(dataset_path, my_folder)+\"\\labels\"):\n",
    "            \n",
    "            cropped_img_name = f\"{label_name}_{counter}.jpg\"\n",
    "            #cropped_img_path = os.path.join(cropped_folder_path, cropped_img_name)\n",
    "            cropped_img_path = cropped_folder_path+\"/\"+cropped_img_name\n",
    "            print(cropped_img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [*{*l}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dam"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "570feb405e2e27c949193ac68f46852414290d515b0ba6e5d90d076ed2284471"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
